{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k  $50-75k  \\\n",
      "0            Agnostic     27       34       60       81       76      137   \n",
      "1             Atheist     12       27       37       52       35       70   \n",
      "2            Buddhist     27       21       30       34       33       58   \n",
      "3            Catholic    418      617      732      670      638     1116   \n",
      "4  Don’t know/refused     15       14       15       11       10       35   \n",
      "\n",
      "   $75-100k  $100-150k  >150k  Don't know/refused  \n",
      "0       122        109     84                  96  \n",
      "1        73         59     74                  76  \n",
      "2        62         39     53                  54  \n",
      "3       949        792    633                1489  \n",
      "4        21         17     18                 116  \n"
     ]
    }
   ],
   "source": [
    "#데이터프레임의 열은 파이썬의 변수와 비슷한 역할을 합니다. \n",
    "#예를 들어 ebola데이터프레임 열은 사망한 날짜(Date), 발병 국가(Case_Guinea)등의\n",
    "#데이터를 저장하고 있습니다. \n",
    "#하지만 이번에 다루는 데이터프레임의 열은 열 자체가 어떤 값을 의미합니다. \n",
    "#그러다 보니 데이터프레임의 열이 옆보다 길게 늘어선 형태가 된다. 바로 이것을\n",
    "#넓은 데이터라고 합니다. \n",
    "#melt메서드는 데이터프레임을 깔끔한 데이터로 정이하는데 유용한 메서드로 제공됩니다. \n",
    "#1개의 열만 고정하고 나머지 열을 행으로 바꾸기 \n",
    "#이번에 사용할 데이터집합은 퓨 리서치 센터에서 조사한 \"미국의 소득과 종교\"라는 데이터입니다. \n",
    "#이 데이터프레임에는 총 11개의 열이 있습니다. \n",
    "import pandas as pd \n",
    "pew = pd.read_csv(\"c:\\\\work\\\\pew.csv\")\n",
    "print(pew.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   religion  <$10k  $10-20k  $20-30k  $30-40k  $40-50k\n",
      "0                  Agnostic     27       34       60       81       76\n",
      "1                   Atheist     12       27       37       52       35\n",
      "2                  Buddhist     27       21       30       34       33\n",
      "3                  Catholic    418      617      732      670      638\n",
      "4        Don’t know/refused     15       14       15       11       10\n",
      "5          Evangelical Prot    575      869     1064      982      881\n",
      "6                     Hindu      1        9        7        9       11\n",
      "7   Historically Black Prot    228      244      236      238      197\n",
      "8         Jehovah's Witness     20       27       24       24       21\n",
      "9                    Jewish     19       19       25       25       30\n",
      "10            Mainline Prot    289      495      619      655      651\n",
      "11                   Mormon     29       40       48       51       56\n",
      "12                   Muslim      6        7        9       10        9\n",
      "13                 Orthodox     13       17       23       32       32\n",
      "14          Other Christian      9        7       11       13       13\n",
      "15             Other Faiths     20       33       40       46       49\n",
      "16    Other World Religions      5        2        3        4        2\n",
      "17             Unaffiliated    217      299      374      365      341\n"
     ]
    }
   ],
   "source": [
    "#6개의 열만 출력해 볼까요? 그러면 종교와 소득 정보가 출력됩니다. \n",
    "#하지만 이 상태는 소득 정보가 열을 구성하고 있죠. 만약 소득 정보 열을 행 데이터로 \n",
    "#옮기고 싶다면 어떻게 할까요?\n",
    "print(pew.iloc[:, 0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion variable  value\n",
      "0            Agnostic    <$10k     27\n",
      "1             Atheist    <$10k     12\n",
      "2            Buddhist    <$10k     27\n",
      "3            Catholic    <$10k    418\n",
      "4  Don’t know/refused    <$10k     15\n"
     ]
    }
   ],
   "source": [
    "#다음을 입력하여 결과를 살펴봅니다. id_vars인자값으로 지정한 열(religion)을 제외한 나머지 소득 정보 열\n",
    "#($10k,$10-20k,...)이 variable열로 정리되고 소득정보 열의 행 데이터도 value열로 정리되었습니다. \n",
    "#바로 이 과정을 \"religion\"열을 고정하여 피벗했다\"라고 합니다.\n",
    "pew_long = pd.melt(pew, id_vars=\"religion\")\n",
    "print(pew_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             religion income  count\n",
      "0            Agnostic  <$10k     27\n",
      "1             Atheist  <$10k     12\n",
      "2            Buddhist  <$10k     27\n",
      "3            Catholic  <$10k    418\n",
      "4  Don’t know/refused  <$10k     15\n"
     ]
    }
   ],
   "source": [
    "#그러면 variable, value열의 열 이름은 어떻게 바꿀 수 있을까요? var_name, value_name인자값을 사용하면 됩니다.\n",
    "pew_long = pd.melt(pew, id_vars=\"religion\", var_name=\"income\", value_name=\"count\")\n",
    "print(pew_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered  wk1   wk2  \\\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26   87  82.0   \n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02   91  87.0   \n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08   81  70.0   \n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21   76  76.0   \n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15   57  34.0   \n",
      "\n",
      "    wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  \n",
      "0  72.0  77.0  87.0  94.0  99.0   NaN   NaN   NaN   NaN  \n",
      "1  92.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  68.0  67.0  66.0  57.0  54.0  53.0  51.0  51.0  51.0  \n",
      "3  72.0  69.0  67.0  65.0  55.0  59.0  62.0  61.0  61.0  \n",
      "4  25.0  17.0  17.0  31.0  36.0  49.0  53.0  57.0  64.0  \n"
     ]
    }
   ],
   "source": [
    "#2개 이상의 열을 고정하고 나머지 열을 행으로 바꾸기 \n",
    "#이번에는 빌보드 챠트 데이터를 사용하여 실습을 진행합니다. 2개 이상의 열을 고정하고 \n",
    "#나머지 열을 행으로 바꾸면 어떻게 될까요? \n",
    "billboard = pd.read_csv(\"c:\\\\work\\\\billboard.csv\")\n",
    "print(billboard.iloc[0:5, 0:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "#다음은 year, artist, track, time, date.entered열을 모두 고정하고 나머지 열을 피벗한 것입니다.\n",
    "billboard_long = pd.melt(billboard, id_vars=[\"year\",\"artist\",\"track\",\n",
    "        \"time\",\"date.entered\"], var_name=\"week\", value_name=\"rating\")\n",
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Day', 'Cases_Guinea', 'Cases_Liberia', 'Cases_SierraLeone',\n",
      "       'Cases_Nigeria', 'Cases_Senegal', 'Cases_UnitedStates', 'Cases_Spain',\n",
      "       'Cases_Mali', 'Deaths_Guinea', 'Deaths_Liberia', 'Deaths_SierraLeone',\n",
      "       'Deaths_Nigeria', 'Deaths_Senegal', 'Deaths_UnitedStates',\n",
      "       'Deaths_Spain', 'Deaths_Mali'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#열 이름 관리하기\n",
    "#하나의 열이 여러 의미를 가지는 경우\n",
    "#어떤 열은 여러 가지 의미를 가지고 있을 수 있습니다. 예를 들어 ebola데이터집합의 열중 하나인 Deaths_Guinea는 \n",
    "#\"사명자 수\"와 \"나라 이름\"을 합쳐 만든 이름입니다. \n",
    "#다음은 ebola데이터를 불러온 다음 0, 1, 2, 3, 10, 11열의 5개 데이터만 확인한 것입니다. \n",
    "ebola = pd.read_csv(\"c:\\\\work\\\\country_timeseries.csv\")\n",
    "print(ebola.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day  Cases_Guinea  Cases_Liberia  Deaths_Guinea  Deaths_Liberia\n",
      "0    1/5/2015  289        2776.0            NaN         1786.0             NaN\n",
      "1    1/4/2015  288        2775.0            NaN         1781.0             NaN\n",
      "2    1/3/2015  287        2769.0         8166.0         1767.0          3496.0\n",
      "3    1/2/2015  286           NaN         8157.0            NaN          3496.0\n",
      "4  12/31/2014  284        2730.0         8115.0         1739.0          3471.0\n"
     ]
    }
   ],
   "source": [
    "print(ebola.iloc[:5, [0, 1, 2, 3, 10, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0\n",
      "3    1/2/2015  286  Cases_Guinea     NaN\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0\n"
     ]
    }
   ],
   "source": [
    "#일단 Date와 Day를 고정하고 나머지를 행으로 피벗하겠습니다. 그러면 각 나라별 사망자 수를 \n",
    "#행으로 볼 수 있어 편리합니다. \n",
    "ebola_long = pd.melt(ebola, id_vars=[\"Date\", \"Day\"])\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Cases, Guinea]\n",
      "1    [Cases, Guinea]\n",
      "2    [Cases, Guinea]\n",
      "3    [Cases, Guinea]\n",
      "4    [Cases, Guinea]\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#split메서드로 열 이름 분리하기\n",
    "#Cases_Guinea와 같이 2개 이상의 의미를 가지고 있는 열 이름은 밑줄(_)을 기준으로 Cases, Guinea와 같은 방법으로\n",
    "#분리할 수 있습니다. 이때 열 이름을 분리하려면 split메서드를 사용하면 됩니다. split메서드는 기본적으로 공백을\n",
    "#기준으로 문자열을 자릅니다. \n",
    "#split메서드에 \"_\"를 전달하면 Cases_Guinea를 Cases, Guinea로 분리할 수 있습니다.\n",
    "variable_split = ebola_long.variable.str.split(\"_\")\n",
    "print(variable_split[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#이떄 variable_split에 저장된 값의 자료형은 시리즈이고 각각의 시리즈에 저장된 값(열이름)의 \n",
    "#자료형은 리스트입니다.\n",
    "print(type(variable_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(variable_split[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Cases\n",
      "1    Cases\n",
      "2    Cases\n",
      "3    Cases\n",
      "4    Cases\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#이때 앞에서 구한 리스트의 0번째 인덱스에 담긴 문자열은 발병(Cases)와 죽음(Deaths)같은 상태를 의미하고\n",
    "#1번째 인덱스에 담긴 문자열은 나라 이름을 의미합니다. 이제 이 문자열을 분리하여 데이터프레임의 새로운 열로\n",
    "#추가하면 됩니다. get메서드를 사용하여 0,1번째 인덱스의 데이터를 한번에 추출한 것입니다.\n",
    "status_values = variable_split.str.get(0)\n",
    "country_values = variable_split.str.get(1)\n",
    "print(status_values[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1947    Deaths\n",
      "1948    Deaths\n",
      "1949    Deaths\n",
      "1950    Deaths\n",
      "1951    Deaths\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(status_values[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Guinea\n",
      "1    Guinea\n",
      "2    Guinea\n",
      "3    Guinea\n",
      "4    Guinea\n",
      "Name: variable, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(country_values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "#다음은 앞에서 분리한 문자열을 status, country라는 열 이름으로 데이터프레임에 추가한 코드입니다.\n",
    "ebola_long[\"status\"] = status_values\n",
    "ebola_long[\"country\"] = country_values\n",
    "print(ebola_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Day      variable   value status country status country\n",
      "0    1/5/2015  289  Cases_Guinea  2776.0  Cases  Guinea  Cases  Guinea\n",
      "1    1/4/2015  288  Cases_Guinea  2775.0  Cases  Guinea  Cases  Guinea\n",
      "2    1/3/2015  287  Cases_Guinea  2769.0  Cases  Guinea  Cases  Guinea\n",
      "3    1/2/2015  286  Cases_Guinea     NaN  Cases  Guinea  Cases  Guinea\n",
      "4  12/31/2014  284  Cases_Guinea  2730.0  Cases  Guinea  Cases  Guinea\n"
     ]
    }
   ],
   "source": [
    "#concat메서드를 활용하면 split메서드로 분리한 데이터를 바로 데이터프레임에 추가할 수도 있습니다.\n",
    "#다음은 바로 앞에서 실습한 내용을 concat메서드로 바꿔서 실행한 코드입니다.\n",
    "variable_split = ebola_long.variable.str.split(\"_\", expand=True)\n",
    "variable_split.columns = [\"status\",\"country\"]\n",
    "ebola_parsed = pd.concat([ebola_long, variable_split], axis=1)\n",
    "print(ebola_parsed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element  d1    d2    d3  d4    d5  d6  ...  d22   d23  \\\n",
      "0  MX17004  2010      1    tmax NaN   NaN   NaN NaN   NaN NaN  ...  NaN   NaN   \n",
      "1  MX17004  2010      1    tmin NaN   NaN   NaN NaN   NaN NaN  ...  NaN   NaN   \n",
      "2  MX17004  2010      2    tmax NaN  27.3  24.1 NaN   NaN NaN  ...  NaN  29.9   \n",
      "3  MX17004  2010      2    tmin NaN  14.4  14.4 NaN   NaN NaN  ...  NaN  10.7   \n",
      "4  MX17004  2010      3    tmax NaN   NaN   NaN NaN  32.1 NaN  ...  NaN   NaN   \n",
      "\n",
      "   d24  d25  d26  d27  d28  d29   d30  d31  \n",
      "0  NaN  NaN  NaN  NaN  NaN  NaN  27.8  NaN  \n",
      "1  NaN  NaN  NaN  NaN  NaN  NaN  14.5  NaN  \n",
      "2  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN  \n",
      "3  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN  \n",
      "4  NaN  NaN  NaN  NaN  NaN  NaN   NaN  NaN  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "#여러열을 하나로 정리하기\n",
    "#기상 데이터의 여러 열을 하나로 정리하기 - melt, pivot_table메서드\n",
    "#다음은 기상 데이터를 불러와 출력한 것입니다. 날짜열(d1,...d31)에는 각 월별 최고, 최저 온도 데이터가\n",
    "#저장되어 있습니다. 지금은 날짜 열이 옆으로 길게 늘어져 있어 보기 불편합니다. \n",
    "#먼저 날짜열을 행 데이터로 피벗하겠습니다. \n",
    "weather = pd.read_csv(\"c:\\\\work\\\\weather.csv\")\n",
    "print(weather.iloc[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  year  month element day  temp\n",
      "0  MX17004  2010      1    tmax  d1   NaN\n",
      "1  MX17004  2010      1    tmin  d1   NaN\n",
      "2  MX17004  2010      2    tmax  d1   NaN\n",
      "3  MX17004  2010      2    tmin  d1   NaN\n",
      "4  MX17004  2010      3    tmax  d1   NaN\n"
     ]
    }
   ],
   "source": [
    "#다음은 melt메서드로 일별 온도 측정값(d1,d2,...)을 피벗한 것입니다. 그러면 day열에 날짜 열이 정리되고 \n",
    "#날짜 열의 데이터는 temp열에 정리됩니다. 하지만 아직 최고, 최저 온도가 한눈에 잘 들어오지 않습니다. \n",
    "weather_melt = pd.melt(weather, id_vars=[\"id\",\"year\",\"month\",\"element\"], var_name=\"day\",\n",
    "                      value_name=\"temp\")\n",
    "print(weather_melt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element                 tmax  tmin\n",
      "id      year month day            \n",
      "MX17004 2010 1     d30  27.8  14.5\n",
      "             2     d11  29.7  13.4\n",
      "                   d2   27.3  14.4\n",
      "                   d23  29.9  10.7\n",
      "                   d3   24.1  14.4\n",
      "             3     d10  34.5  16.8\n",
      "                   d16  31.1  17.6\n",
      "                   d5   32.1  14.2\n",
      "             4     d27  36.3  16.7\n",
      "             5     d27  33.2  18.2\n",
      "             6     d17  28.0  17.5\n",
      "                   d29  30.1  18.0\n",
      "             7     d3   28.6  17.5\n",
      "                   d14  29.9  16.5\n",
      "             8     d23  26.4  15.0\n",
      "                   d5   29.6  15.8\n",
      "                   d29  28.0  15.3\n",
      "                   d13  29.8  16.5\n",
      "                   d25  29.7  15.6\n",
      "                   d31  25.4  15.4\n",
      "                   d8   29.0  17.3\n",
      "             10    d5   27.0  14.0\n",
      "                   d14  29.5  13.0\n",
      "                   d15  28.7  10.5\n",
      "                   d28  31.2  15.0\n",
      "                   d7   28.1  12.9\n",
      "             11    d2   31.3  16.3\n",
      "                   d5   26.3   7.9\n",
      "                   d27  27.7  14.2\n",
      "                   d26  28.1  12.1\n",
      "                   d4   27.2  12.0\n",
      "             12    d1   29.9  13.8\n",
      "                   d6   27.8  10.5\n"
     ]
    }
   ],
   "source": [
    "#이제 pivot_table메서드를 사용할 차례입니다. pivot_table메서드는 행과 열의 위치를 다시 바꿔 정리해 줍니다. \n",
    "#index인자에는 위치를 그대로 유지할 열 이름을 지정하고, columns인자에는 피벗할 열 이름을 지정하고, values\n",
    "#인자에는 새로운 열의 데이터가 될 열 이름을 지정하면 됩니다. \n",
    "weather_tidy = weather_melt.pivot_table(\n",
    "    index=[\"id\",\"year\",\"month\",\"day\"],\n",
    "    columns=\"element\",\n",
    "    values=\"temp\")\n",
    "print(weather_tidy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element       id  year  month  day  tmax  tmin\n",
      "0        MX17004  2010      1  d30  27.8  14.5\n",
      "1        MX17004  2010      2  d11  29.7  13.4\n",
      "2        MX17004  2010      2   d2  27.3  14.4\n",
      "3        MX17004  2010      2  d23  29.9  10.7\n",
      "4        MX17004  2010      2   d3  24.1  14.4\n"
     ]
    }
   ],
   "source": [
    "#앞에서 구한 데이터프레임의 인덱스를 reset_index메서드로 새로 지정한 것입니다.\n",
    "weather_tidy_flat = weather_tidy.reset_index()\n",
    "print(weather_tidy_flat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 7)\n"
     ]
    }
   ],
   "source": [
    "#중복 데이터 처리하기 \n",
    "#이번에 다룰 빌보드 챠트 데이터는 artist, track, time, date.entered열의 데이터가 반복됩니다.\n",
    "#이런 반복되는 데이터는 따로 관리하는 것이 좋습니다. \n",
    "billboard = pd.read_csv(\"c:\\\\work\\\\billboard.csv\")\n",
    "billboard_long = pd.melt(billboard, id_vars=[\"year\",\"artist\",\"track\",\"time\",\n",
    "                \"date.entered\"], var_name=\"week\", value_name=\"rating\")\n",
    "print(billboard_long.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year        artist                    track  time date.entered week  rating\n",
      "0  2000         2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0\n",
      "1  2000       2Ge+her  The Hardest Part Of ...  3:15   2000-09-02  wk1    91.0\n",
      "2  2000  3 Doors Down               Kryptonite  3:53   2000-04-08  wk1    81.0\n",
      "3  2000  3 Doors Down                    Loser  4:24   2000-10-21  wk1    76.0\n",
      "4  2000      504 Boyz            Wobble Wobble  3:35   2000-04-15  wk1    57.0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_long.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year        artist  track  time date.entered week  rating\n",
      "3     2000  3 Doors Down  Loser  4:24   2000-10-21  wk1    76.0\n",
      "320   2000  3 Doors Down  Loser  4:24   2000-10-21  wk2    76.0\n",
      "637   2000  3 Doors Down  Loser  4:24   2000-10-21  wk3    72.0\n",
      "954   2000  3 Doors Down  Loser  4:24   2000-10-21  wk4    69.0\n",
      "1271  2000  3 Doors Down  Loser  4:24   2000-10-21  wk5    67.0\n"
     ]
    }
   ],
   "source": [
    "#노래 제목이 Loser인 데이터만 따로 모아보면 중복 데이터가 많다는 것을 알 수 있습니다. \n",
    "#예를 들어 가수(artist)는 고유한 값이기 때문에 따로 관리하는 것이 데이터의 일관성을 유지하는데 \n",
    "#더 도움이 됩니다. \n",
    "print(billboard_long[billboard_long.track == \"Loser\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 4)\n"
     ]
    }
   ],
   "source": [
    "#중복 데이터를 가지고 있는 열은 year, artist, track, date입니다. \n",
    "#이 열을 따로 모아 새로운 데이터프레임에 저장합니다.\n",
    "billboard_songs = billboard_long[[\"year\",\"artist\",\"track\",\"time\"]]\n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(317, 4)\n"
     ]
    }
   ],
   "source": [
    "#그런 다음 drop_duplicates메서드로 중복 데이터를 제거합니다.\n",
    "billboard_songs = billboard_songs.drop_duplicates()\n",
    "print(billboard_songs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year          artist                    track  time  id\n",
      "0  2000           2 Pac  Baby Don't Cry (Keep...  4:22   0\n",
      "1  2000         2Ge+her  The Hardest Part Of ...  3:15   1\n",
      "2  2000    3 Doors Down               Kryptonite  3:53   2\n",
      "3  2000    3 Doors Down                    Loser  4:24   3\n",
      "4  2000        504 Boyz            Wobble Wobble  3:35   4\n",
      "5  2000            98^0  Give Me Just One Nig...  3:24   5\n",
      "6  2000         A*Teens            Dancing Queen  3:44   6\n",
      "7  2000         Aaliyah            I Don't Wanna  4:15   7\n",
      "8  2000         Aaliyah                Try Again  4:03   8\n",
      "9  2000  Adams, Yolanda            Open My Heart  5:30   9\n"
     ]
    }
   ],
   "source": [
    "#중복을 제거한 데이터프레임에 다음과 같이 id도 추가합니다. \n",
    "billboard_songs[\"id\"] = range(len(billboard_songs))\n",
    "print(billboard_songs.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24092, 8)\n"
     ]
    }
   ],
   "source": [
    "#merge메서드를 사용해서 노래 정보와 주간 순위 데이터를 합친 것입니다. \n",
    "billboard_ratings = billboard_long.merge(billboard_songs, on=[\"year\",\"artist\",\"track\",\"time\"])\n",
    "print(billboard_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year artist                    track  time date.entered week  rating  id\n",
      "0  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk1    87.0   0\n",
      "1  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk2    82.0   0\n",
      "2  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk3    72.0   0\n",
      "3  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk4    77.0   0\n",
      "4  2000  2 Pac  Baby Don't Cry (Keep...  4:22   2000-02-26  wk5    87.0   0\n"
     ]
    }
   ],
   "source": [
    "print(billboard_ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-01.csv\n",
      "\n",
      "c:\\work\\fhv_tripdata_2015-01.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-02.csv\n",
      "\n",
      "c:\\work\\fhv_tripdata_2015-02.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-03.csv\n",
      "\n",
      "c:\\work\\fhv_tripdata_2015-03.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-04.csv\n",
      "\n",
      "c:\\work\\fhv_tripdata_2015-04.csv\n",
      "https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2015-05.csv\n",
      "\n",
      "c:\\work\\fhv_tripdata_2015-05.csv\n"
     ]
    }
   ],
   "source": [
    "#대용량 데이터 처리하기\n",
    "#여러개로 나누어진 데이터 불러오기 \n",
    "#데이터는 필요에 따라 나누어 저장하기도 합니다. 데이터를 나누어서 저장하면 용량이 작아져 데이터를 저장하거나\n",
    "#다른 사람에게 공유할 때 유용하죠. \n",
    "#뉴욕 택시 데이터 준비하기\n",
    "#뉴욕 택시 데이터는 13억 대의 뉴욕 택시에 대한 정보를 가지고 있습니다. 파일의 갯수도 140개정도 됩니다. \n",
    "#이번 실습은 5개의 데이터만 사용합니다. 네트워크의 상태에 따라 5분에서 10분정도 걸립니다. \n",
    "import os \n",
    "import urllib.request\n",
    "\n",
    "with open(\"c:\\\\work\\\\raw_data_urls.txt\", \"r\") as data_urls:\n",
    "    for line, url in enumerate(data_urls):\n",
    "        if line == 5:\n",
    "            break\n",
    "        fn = url.split(\"/\")[-1].strip()\n",
    "        fp = os.path.join(\"c:\\\\work\\\\\", fn)\n",
    "        print(url)\n",
    "        print(fp)\n",
    "        urllib.request.urlretrieve(url, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\work\\\\fhv_tripdata_2015-01.csv', 'c:\\\\work\\\\fhv_tripdata_2015-02.csv', 'c:\\\\work\\\\fhv_tripdata_2015-03.csv', 'c:\\\\work\\\\fhv_tripdata_2015-04.csv', 'c:\\\\work\\\\fhv_tripdata_2015-05.csv']\n"
     ]
    }
   ],
   "source": [
    "#내려 받은 데이터는 c:\\work폴더에 \"fhv_tripdata_YYYY_MM.csv\"라는 이름으로 저장됩니다.\n",
    "#이제 판다스로 데이터를 불러오면 됩니다. \n",
    "import glob\n",
    "nyc_taxi_data = glob.glob(\"c:\\\\work\\\\fhv_*\")\n",
    "print(nyc_taxi_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#각각의 파일을 데이터프레임으로 저장\n",
    "taxi1 = pd.read_csv(nyc_taxi_data[0])\n",
    "taxi2 = pd.read_csv(nyc_taxi_data[1])\n",
    "taxi3 = pd.read_csv(nyc_taxi_data[2])\n",
    "taxi4 = pd.read_csv(nyc_taxi_data[3])\n",
    "taxi5 = pd.read_csv(nyc_taxi_data[4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-01-01 00:30:00         NaN\n",
      "1               B00013  2015-01-01 01:22:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00013  2015-02-01 00:00:00         NaN\n",
      "1               B00013  2015-02-01 00:01:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00029  2015-03-01 00:02:00       213.0\n",
      "1               B00029  2015-03-01 00:03:00        51.0\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-04-01 04:30:00         NaN\n",
      "1               B00001  2015-04-01 06:00:00         NaN\n",
      "  Dispatching_base_num          Pickup_date  locationID\n",
      "0               B00001  2015-05-01 04:30:00         NaN\n",
      "1               B00001  2015-05-01 05:00:00         NaN\n"
     ]
    }
   ],
   "source": [
    "#데이터를 잘 불러왔는지 확인\n",
    "print(taxi1.head(n=2))\n",
    "print(taxi2.head(n=2))\n",
    "print(taxi3.head(n=2))\n",
    "print(taxi4.head(n=2))\n",
    "print(taxi5.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2746033, 3)\n",
      "(3126401, 3)\n",
      "(3281427, 3)\n",
      "(3917789, 3)\n",
      "(4296067, 3)\n"
     ]
    }
   ],
   "source": [
    "#각 데이터의 구조, 즉 행과 열을 확인해 봅니다. 데이터가 꽤 크다는 것을 알 수 있습니다.\n",
    "print(taxi1.shape)\n",
    "print(taxi2.shape)\n",
    "print(taxi3.shape)\n",
    "print(taxi4.shape)\n",
    "print(taxi5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17367717, 3)\n"
     ]
    }
   ],
   "source": [
    "#이제 데이터 처리를 위해 각 데이터프레임을 연결해야 합니다. \n",
    "#다음은 concat메서드로 모든 데이터프레임을 연결한 것입니다.\n",
    "#대략 1천7백만건 \n",
    "taxi = pd.concat([taxi1,taxi2,taxi3,taxi4,taxi5])\n",
    "print(taxi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
